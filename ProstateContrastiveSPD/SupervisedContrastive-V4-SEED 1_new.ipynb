{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "#os.environ[\"OMP_NUM_THREADS\"] = str(1)\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "torch.set_num_threads(1)\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "SEED = 1\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from Utils import EarlyStopping\n",
    "from spdnetwork.optimizers import MixOptimizer\n",
    "from Models import Contrastive_CB3_SPD_WithOutBire, Contrastive_CB3_SPD_1Bire, Contrastive_CB3_Combined, Contrastive_CB3\n",
    "from ProstatexDataset import ProstatexDataset\n",
    "from DatasetManagement import DatasetManagement\n",
    "from Losses import NTXentLoss, TripletLoss, NTXentLossLp\n",
    "import json\n",
    "import copy\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import math\n",
    "# device = torch.device('cpu')\n",
    "# device = torch.device('cuda:0')\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "cpu = torch.device('cpu')\n",
    "#'1.3.4' pandas version\n",
    "def reset_random_seeds():\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "    os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mining_config(args):\n",
    "    if args['loss_function']['mining']['positives'] is None or args['loss_function']['mining']['negatives'] is None:\n",
    "        return 'no-mining'\n",
    "    else:\n",
    "        rules = {\n",
    "            'easy': 'e',\n",
    "            'hard': 'h',\n",
    "            'semihard': 'sh'\n",
    "        }\n",
    "        mining_name ='{}p-{}n'.format(\n",
    "            rules[args['loss_function']['mining']['positives']],\n",
    "            rules[args['loss_function']['mining']['negatives']]\n",
    "        )\n",
    "        return mining_name\n",
    "\n",
    "def get_loss_function(args):\n",
    "    if args['loss_function']['kind'] == 'TripletLoss':\n",
    "        loss_name = '{}_ts_ephn_m_{}'.format(\n",
    "            args['loss_function']['kind'],\n",
    "            args['loss_function']['margin']\n",
    "        )\n",
    "    elif args['loss_function']['kind'] == 'n_pair':\n",
    "        loss_name = args['loss_function']['kind']\n",
    "\n",
    "    elif args['loss_function']['kind'] == 'NTXentLoss':\n",
    "        loss_name = '{}_T_{}' .format(\n",
    "            args['loss_function']['kind'],\n",
    "            args['loss_function']['temperature']\n",
    "        )\n",
    "    \n",
    "    elif args['loss_function']['kind'] == 'SupervisedContrastiveLoss':\n",
    "        loss_name = '{}_T_{}' .format(\n",
    "            args['loss_function']['kind'],\n",
    "            args['loss_function']['temperature']\n",
    "        )\n",
    "\n",
    "    elif args['loss_function']['kind'] == 'max_margin':\n",
    "        loss_name = '{}_met_{}_mar_{}' .format(\n",
    "            args['loss_function']['kind'],\n",
    "            args['loss_function']['metric'],\n",
    "            args['loss_function']['margin']\n",
    "        )\n",
    "\n",
    "    return loss_name\n",
    "\n",
    "def get_optimizer(args):\n",
    "    if args['optimizer']['kind'] == 'Mix_RMSprop':\n",
    "        optimizer_name = '{}_mom_{}_lr_{}'.format(\n",
    "            args['optimizer']['kind'],\n",
    "            args['optimizer']['momentum'],\n",
    "            args['optimizer']['learning_rate']\n",
    "        )\n",
    "\n",
    "    if args['optimizer']['kind'] == 'RMSprop':\n",
    "        optimizer_name = '{}_mom_{}_lr_{}'.format(\n",
    "            args['optimizer']['kind'],\n",
    "            args['optimizer']['momentum'],\n",
    "            args['optimizer']['learning_rate']\n",
    "        )\n",
    "    \n",
    "    elif args['optimizer']['kind'] == 'Adam':\n",
    "        optimizer_name = '{}_lr_{}'.format(\n",
    "            args['optimizer']['kind'],\n",
    "            args['optimizer']['learning_rate']\n",
    "        )\n",
    "    return optimizer_name\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_contrastive(model, train_data, val_data, args):\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    early_stopping = EarlyStopping(patience=args['epochs']*0.05)\n",
    "    \n",
    "    if args['loss_function']['kind'] == 'NTXentLoss':\n",
    "        criterion = NTXentLoss(\n",
    "            temperature = args['loss_function']['temperature'],\n",
    "            positives = args['loss_function']['mining']['positives'],\n",
    "            negatives = args['loss_function']['mining']['negatives']\n",
    "        )\n",
    "        \n",
    "    elif args['loss_function']['kind'] == 'CombinedLoss':\n",
    "        criterion1 = NTXentLoss(\n",
    "            temperature = args['loss_function']['temperature'],\n",
    "            positives = args['loss_function']['mining']['positives'],\n",
    "            negatives = args['loss_function']['mining']['negatives']\n",
    "        )\n",
    "        criterion2 = nn.CrossEntropyLoss()\n",
    "        \n",
    "    elif args['loss_function']['kind'] == 'TripletLoss':\n",
    "        criterion = TripletLoss(\n",
    "            margin=args['loss_function']['margin'],\n",
    "            positives = args['loss_function']['mining']['positives'],\n",
    "            negatives = args['loss_function']['mining']['negatives']\n",
    "        )\n",
    "        \n",
    "    elif args['loss_function']['kind'] == 'SupervisedContrastiveLoss':\n",
    "        criterion = SupervisedContrastiveLoss(\n",
    "            temperature=args['loss_function']['temperature'],\n",
    "        )\n",
    "    \n",
    "    elif args['loss_function']['kind'] == 'NTXentLossLp':\n",
    "        \n",
    "        criterion = NTXentLossLp(\n",
    "            temperature = args['loss_function']['temperature'],\n",
    "            positives = args['loss_function']['mining']['positives'],\n",
    "            negatives = args['loss_function']['mining']['negatives']\n",
    "        )\n",
    "        print(\"Training with NTXentLossLp\")\n",
    "    \n",
    "    if args['optimizer']['kind'] == 'Adam':\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=args['optimizer']['learning_rate'])\n",
    "    elif args['optimizer']['kind'] == 'RMSprop':\n",
    "        optimizer = torch.optim.RMSprop(\n",
    "            model.parameters(), \n",
    "            lr=args['optimizer']['learning_rate'],\n",
    "            momentum = args['optimizer']['momentum']\n",
    "        )\n",
    "        \n",
    "    elif args['optimizer']['kind'] == 'RMSprop':\n",
    "        optimizer = torch.optim.RMSprop(\n",
    "            model.parameters(), \n",
    "            lr=args['optimizer']['learning_rate'],\n",
    "            momentum = args['optimizer']['momentum']\n",
    "        )\n",
    "    \n",
    "    elif args['optimizer']['kind'] == 'Mix_RMSprop':\n",
    "        optimizer = torch.optim.RMSprop(\n",
    "            model.parameters(), \n",
    "            lr=args['optimizer']['learning_rate'],\n",
    "            momentum = args['optimizer']['momentum']\n",
    "        )\n",
    "\n",
    "        optimizer = MixOptimizer(parameters = model.parameters(), \n",
    "                                optimizer = torch.optim.RMSprop,                                \n",
    "                                lr = args['optimizer']['learning_rate']                             \n",
    "                                )\n",
    "        \n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset = train_data,\n",
    "        shuffle = False,\n",
    "        batch_size = args['batch_size'],\n",
    "        pin_memory=False\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        dataset = val_data,\n",
    "        shuffle = False,\n",
    "        batch_size = args['batch_size'],\n",
    "        pin_memory=False\n",
    "    )\n",
    "    \n",
    "    #train_loop\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    model.type(torch.double)\n",
    "    for epoch in range (args['epochs']):\n",
    "        if early_stopping.early_stop:\n",
    "            break;\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            # print(f\"labels shape: {labels.shape}\")\n",
    "            # print(f\"labels: {labels[0]}\")\n",
    "            for j in range(len(inputs)):\n",
    "                inputs[j] = inputs[j].to(device)\n",
    "            labels = labels.to(device)\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # forward + backward + optimize\n",
    "            logits, out = model(inputs)\n",
    "            outputs = torch.nn.functional.normalize(logits, p=2.0)\n",
    "            \n",
    "            loss1 = criterion1(outputs, labels)\n",
    "            \n",
    "            loss2 = criterion2(out, labels.view(-1).long())\n",
    "\n",
    "            loss = loss1 * 0.2 + loss2 * 0.8  \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()* inputs[0].size(0)\n",
    "        \n",
    "        running_loss = running_loss / len(train_data)\n",
    "        train_losses.append(running_loss) \n",
    "        with torch.no_grad():\n",
    "            #validation_loop\n",
    "            model.eval()\n",
    "            model.to(device)\n",
    "            val_loss = 0.0\n",
    "            for i, data in enumerate(val_loader, 0):\n",
    "                # get the inputs; data is a list of [inputs, labels]\n",
    "\n",
    "                for j in range(len(inputs)):\n",
    "                    inputs[j] = inputs[j].to(device)\n",
    "                labels = labels.to(device)\n",
    "                # forward + backward + optimize\n",
    "                \n",
    "                \n",
    "                logits, out = model(inputs)\n",
    "                outputs = torch.nn.functional.normalize(logits, p=2.0)\n",
    "                \n",
    "                loss1 = criterion1(outputs, labels)\n",
    "                loss2 = criterion2(out, labels.view(-1).long())\n",
    "                loss = loss1 * 0.2 + loss2 * 0.8  \n",
    "\n",
    "                val_loss += loss.item() * inputs[0].size(0)\n",
    "            val_loss = val_loss / len(val_data)\n",
    "            val_losses.append(val_loss)\n",
    "\n",
    "            early_stopping(val_loss)\n",
    "            if (epoch+1) % 1 == 0: #25\n",
    "                print('Epoch {}, val_loss:{:.3f}, train_loss:{:.3f}'.format(epoch+1, val_loss, running_loss ))\n",
    "        \n",
    "        \n",
    "    return {\n",
    "        'loss': train_losses,\n",
    "        'val_loss': val_losses,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_linear_top(model, train_data):\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.svm import SVC\n",
    "    \n",
    "    logistic_regressor = LogisticRegression(random_state=SEED)\n",
    "    svm = SVC(kernel='linear', probability=True, random_state= SEED)\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset = train_data,\n",
    "        shuffle = False,\n",
    "        batch_size = len(train_data),\n",
    "        pin_memory=False\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        #train_loop\n",
    "        model.train()\n",
    "        model.to(device)\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            #ADD\n",
    "            for j in range(len(inputs)):\n",
    "                inputs[j] = inputs[j].to(device)\n",
    "            labels = labels.to(device)\n",
    "            #----\n",
    "            #print(\"Antes del input\")\n",
    "            logits, _ = model(inputs)\n",
    "            #print(\"Despu√©s del input\")\n",
    "            outputs = torch.nn.functional.normalize(logits, p=2.0)\n",
    "            labels = torch.squeeze(labels, dim=1)\n",
    "\n",
    "            #ADD\n",
    "            outputs = outputs.cpu()\n",
    "            labels = labels.cpu()\n",
    "            #---\n",
    "            logistic_regressor.fit(outputs.numpy(), labels.numpy())\n",
    "            svm.fit(outputs.numpy(), labels.numpy())\n",
    "            # print(\"labels shape\", labels.shape)\n",
    "            \n",
    "    print('finished linear training')\n",
    "    return {\n",
    "        'svm': svm, \n",
    "        'logistic_regression': logistic_regressor\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, classifiers, test_data):\n",
    "    import joblib\n",
    "    \n",
    "    \n",
    "    \n",
    "    svm = classifiers['svm']\n",
    "    logistic_regressor = classifiers['logistic_regression']\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset = test_data,\n",
    "        shuffle = False,\n",
    "        batch_size = len(test_data),\n",
    "        pin_memory=False\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        #train_loop\n",
    "        model.eval()\n",
    "        model.to(device)\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            #ADD\n",
    "            for j in range(len(inputs)):\n",
    "                inputs[j] = inputs[j].to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            #---\n",
    "            logits, _ = model(inputs)\n",
    "            outputs = torch.nn.functional.normalize(logits, p=2.0)\n",
    "            #labels = torch.squeeze(labels, dim=1)\n",
    "            #print(\"labels shape\", labels.shape)\n",
    "            #print(\"embeddings shape\", outputs.shape)\n",
    "            #ADD\n",
    "            outputs = outputs.cpu()\n",
    "            labels = labels.cpu()\n",
    "            #---\n",
    "            \n",
    "            lr_probs = logistic_regressor.predict_proba(outputs.numpy())[:,1]\n",
    "            svm_probs = svm.predict_proba(outputs.numpy())[:,1]\n",
    "            \n",
    "            \n",
    "    print('finished linear training')\n",
    "    return {\n",
    "        'svm_probs': svm_probs, \n",
    "        'lr_probs': lr_probs\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fold_of_data(kfold_number, train_data_percentage):\n",
    "\n",
    "\n",
    "    if train_data_percentage is not None:\n",
    "        FOLD_IDEX_PATH = '/data/json_index_shuffle.json'\n",
    "        print(f'-------Cargando los datos del JSON revuelto con el {train_data_percentage*100} % en el fold {kfold_number+1}-------')\n",
    "    else:\n",
    "        FOLD_IDEX_PATH = '/data/picai_folds_indexes.json'\n",
    "        print(\"^^^^^^^^^^Entrenando con todo el Dataset^^^^^^^^^^\")\n",
    "    \n",
    "    fold_indexes = open(FOLD_IDEX_PATH, 'r')\n",
    "    indexdes = json.load(fold_indexes)\n",
    "\n",
    "        \n",
    "    training_target_kfold = 'Fold_{}_train'.format(kfold_number)\n",
    "    validation_target_kfold = 'Fold_{}_val'.format(kfold_number)\n",
    "\n",
    "    BASE_PATH = '/data/'\n",
    "    JSON_PATH = os.path.join(BASE_PATH, 'info-12x32x32.json')\n",
    "    IMAGES_PATH = os.path.join(BASE_PATH, 'size-12x32x32')\n",
    "    file = open(JSON_PATH, 'r')\n",
    "\n",
    "    metadata = json.load(file)\n",
    "    file_names = os.listdir(IMAGES_PATH)\n",
    "\n",
    "    X_train = []\n",
    "    Y_train = []\n",
    "    \n",
    "    ids_train = []\n",
    "    ids_val = []\n",
    "\n",
    "    X_validation = []\n",
    "    Y_validation = []\n",
    "    \n",
    "    idx_count = 0 #Contador para ir sabiendo cuantos voy cargando\n",
    "    \n",
    "    if train_data_percentage is not None:\n",
    "        target_stop = int(train_data_percentage * len(indexdes[training_target_kfold])) #Hasta que idx voy a entrenar\n",
    "        print(train_data_percentage)\n",
    "    \n",
    "    if train_data_percentage is not None:   \n",
    "        print(\"Entrenando con porcentajes\")\n",
    "        for patient_id in indexdes[training_target_kfold]:\n",
    "            idx_count+=1\n",
    "            file_name = '{}.npy'.format(patient_id)\n",
    "            img = np.load(os.path.join(IMAGES_PATH, file_name))\n",
    "            X_train.append(img)\n",
    "            ids_train.append(patient_id)\n",
    "            print(\"Entrenando con porcentajes\")\n",
    "    \n",
    "            y = metadata[patient_id]['label']\n",
    "            Y_train.append(y)\n",
    "            \n",
    "            if idx_count == target_stop:\n",
    "                break;\n",
    "    else:  \n",
    "        print(\"Entrenando sin porcentajes\") \n",
    "        for patient_id in indexdes[training_target_kfold]:\n",
    "            \n",
    "            file_name = '{}.npy'.format(patient_id)\n",
    "            img = np.load(os.path.join(IMAGES_PATH, file_name))\n",
    "            X_train.append(img)\n",
    "            ids_train.append(patient_id)\n",
    "    \n",
    "            y = metadata[patient_id]['label']\n",
    "            Y_train.append(y)\n",
    "        \n",
    "        \n",
    "    for patient_id in indexdes[validation_target_kfold]:\n",
    "        file_name = '{}.npy'.format(patient_id)\n",
    "        img = np.load(os.path.join(IMAGES_PATH, file_name))\n",
    "        X_validation.append(img)\n",
    "        ids_val.append(patient_id)\n",
    "\n",
    "        y = metadata[patient_id]['label']\n",
    "        Y_validation.append(y)\n",
    "        \n",
    "    return np.array(X_train), np.array(X_validation), np.array(Y_train), np.array(Y_validation), ids_train, ids_val, indexdes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_k_fold(args):\n",
    "    current_fold = 0\n",
    "    train_data_percentage = args['subsampling_strategy']['percentage']\n",
    "    optimizer_name = get_optimizer(args)\n",
    "    mining_name = get_mining_config(args)   \n",
    "    base_path = '/data/Experiments/'\n",
    "\n",
    "    if train_data_percentage is not None:\n",
    "        percent_path = os.path.join(base_path, f'Experiments_with_{train_data_percentage*100}%/')\n",
    "        if not os.path.exists(percent_path):\n",
    "            os.makedirs(percent_path)\n",
    "            \n",
    "        print(f'****** Trainning with the {train_data_percentage*100}% data******')\n",
    "        base_path = percent_path\n",
    "        \n",
    "        \n",
    "    \n",
    "    loss_path = os.path.join(base_path, 'losses')\n",
    "    if not os.path.exists(loss_path):\n",
    "        os.makedirs(loss_path)\n",
    "        \n",
    "       \n",
    "    \n",
    "    for fold_number in range(0,5):\n",
    "            best_loss = float('inf') \n",
    "            current_fold += 1\n",
    "            print(f'******** Fold {current_fold} ********')\n",
    "\n",
    "            x_train, x_validation ,y_train, y_validation, ids_train, ids_val, indexdes = get_fold_of_data(fold_number, train_data_percentage)\n",
    "            train_dataset = DatasetManagement(x_train, y_train)\n",
    "            val_dataset = DatasetManagement(x_validation, y_validation)\n",
    "            test_dataset = val_dataset\n",
    "\n",
    "\n",
    "            if train_data_percentage is not None:\n",
    "                #Saving the JSON with ids selected for n%\n",
    "                path_json_idx = os.path.join(base_path, f'JSONs folds')\n",
    "                if not os.path.exists(path_json_idx):\n",
    "                    os.makedirs(path_json_idx)\n",
    "\n",
    "                path_json_idx_plus_name = os.path.join(path_json_idx, f'JSON_idx_fold_{current_fold}')\n",
    "\n",
    "                with open(path_json_idx_plus_name, 'w') as f:\n",
    "                    json.dump(indexdes, f)\n",
    "\n",
    "\n",
    "            correct_fold_list = []\n",
    "        \n",
    "            for i in range (len(ids_val)):\n",
    "                correct_fold_list.append('test')\n",
    "                    \n",
    "\n",
    "            \n",
    "            if args['backbone_name'] == 'Contrastive_CB3_SPD_1Bire':\n",
    "                model = Contrastive_CB3_SPD_1Bire(device, args['target_shape'], args['sequence_embedding_features'], 'contrastive')\n",
    "                print('loaded Contrastive_CB3_SPD_1Bire model')\n",
    "                \n",
    "            if args['backbone_name'] == 'Contrastive_CB3_Combined':\n",
    "                model = Contrastive_CB3_Combined(device, args['target_shape'], args['sequence_embedding_features'], 'contrastive')\n",
    "                print('loaded Contrastive_CB3_Combined model')\n",
    "                \n",
    "            if args['backbone_name'] == 'Contrastive_CB3':\n",
    "                model = Contrastive_CB3(device, args['target_shape'], args['sequence_embedding_features'], 'contrastive')\n",
    "                print('loaded Contrastive_CB3 model')\n",
    "                \n",
    "            if args['backbone_name'] == 'Contrastive_CB3_SPD_WithOutBire':\n",
    "                model = Contrastive_CB3_SPD_WithOutBire(device, args['target_shape'], args['sequence_embedding_features'], 'contrastive')\n",
    "                print('loaded Contrastive_CB3_SPD_WithOutBire model')\n",
    "                \n",
    "                \n",
    "            history = fit_contrastive(model, train_dataset, val_dataset, args)\n",
    "            validation_loss = history['val_loss'][-1]\n",
    "            \n",
    "            plt.plot(history['loss'], label = 'loss')\n",
    "            plt.plot(history['val_loss'], label = 'val_loss')\n",
    "            plt.legend()\n",
    "            plt.savefig(os.path.join(loss_path, f'loss_fold_{current_fold}.png'))\n",
    "            plt.show()\n",
    "            plt.close() #PARA QUE NO SE SOBREPONGA\n",
    "            classifiers = fit_linear_top(model, train_dataset)\n",
    "            probs = evaluate(model, classifiers, test_dataset)\n",
    "        \n",
    "            directory_models = os.path.join(base_path, 'models')\n",
    "            if not os.path.exists(directory_models):\n",
    "                os.makedirs(directory_models)\n",
    "            \n",
    "            \n",
    "            joblib.dump(\n",
    "                classifiers['svm'],\n",
    "                base_path+'models/svm_fold_{}.pkl'.format(current_fold)\n",
    "            )\n",
    "            joblib.dump(\n",
    "                classifiers['logistic_regression'],\n",
    "                base_path+'models/lr_fold_{}.pkl'.format(current_fold)\n",
    "            )\n",
    "\n",
    "            directory_results = os.path.join(base_path, 'results')\n",
    "            if not os.path.exists(directory_results):\n",
    "                os.makedirs(directory_results)\n",
    "\n",
    "            kfold_dataframe = pd.DataFrame(\n",
    "                {\n",
    "                 'indexes': ids_val,\n",
    "                 'folds': correct_fold_list,   \n",
    "                 'labels': y_validation.tolist(),\n",
    "                 'lr_probs': probs['lr_probs'].tolist(),\n",
    "                 'svm_probs': probs['svm_probs'].tolist()\n",
    "                }\n",
    "            )\n",
    "            kfold_dataframe.to_csv('{}/results/kfold_results_{}.csv'.format(base_path, current_fold))            \n",
    "            \n",
    "            if validation_loss < best_loss:\n",
    "                best_loss = validation_loss\n",
    "                torch.save(\n",
    "                    model.state_dict(), \n",
    "                    base_path+'models/mertash_contrastive_fold_{}.pt'.format(current_fold)\n",
    "                )            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SIN PORCENTAJES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******** Fold 1 ********\n",
      "^^^^^^^^^^Entrenando con todo el Dataset^^^^^^^^^^\n",
      "Entrenando sin porcentajes\n",
      "loaded Contrastive_CB3_Combined model\n",
      "Epoch 1, val_loss:0.236, train_loss:0.512\n",
      "Epoch 2, val_loss:0.224, train_loss:0.527\n",
      "Epoch 3, val_loss:0.206, train_loss:0.469\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished linear training\n",
      "finished linear training\n",
      "******** Fold 2 ********\n",
      "^^^^^^^^^^Entrenando con todo el Dataset^^^^^^^^^^\n",
      "Entrenando sin porcentajes\n",
      "loaded Contrastive_CB3_Combined model\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 28\u001b[0m\n\u001b[1;32m      1\u001b[0m args \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubsampling_strategy\u001b[39m\u001b[38;5;124m'\u001b[39m:{\n\u001b[1;32m      3\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubsampling_criteria\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m     27\u001b[0m                     }\n\u001b[0;32m---> 28\u001b[0m \u001b[43mrun_k_fold\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 71\u001b[0m, in \u001b[0;36mrun_k_fold\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     67\u001b[0m     model \u001b[38;5;241m=\u001b[39m Contrastive_CB3_SPD_WithOutBire(device, args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget_shape\u001b[39m\u001b[38;5;124m'\u001b[39m], args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msequence_embedding_features\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontrastive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloaded Contrastive_CB3_SPD_WithOutBire model\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 71\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mfit_contrastive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m validation_loss \u001b[38;5;241m=\u001b[39m history[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     74\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m], label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[11], line 113\u001b[0m, in \u001b[0;36mfit_contrastive\u001b[0;34m(model, train_data, val_data, args)\u001b[0m\n\u001b[1;32m    111\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss1 \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.2\u001b[39m \u001b[38;5;241m+\u001b[39m loss2 \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.8\u001b[39m  \n\u001b[1;32m    112\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m--> 113\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m     running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;241m*\u001b[39m inputs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    117\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m running_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_data)\n",
      "File \u001b[0;32m/data/ProstateContrastiveSPD/spdnetwork/optimizers.py:104\u001b[0m, in \u001b[0;36mMixOptimizer.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;66;03m# Doing the step for each Riemannian optimizer.\u001b[39;00m\n\u001b[0;32m--> 104\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstiefel_optim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstiefel_block_optim\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspd_optim\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m/data/ProstateContrastiveSPD/spdnetwork/optimizers.py:17\u001b[0m, in \u001b[0;36mStiefelOptim.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m W \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameters:\n\u001b[1;32m     16\u001b[0m     dir_tan\u001b[38;5;241m=\u001b[39mproj_tanX_stiefel(W\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mdata,W\u001b[38;5;241m.\u001b[39mdata)\n\u001b[0;32m---> 17\u001b[0m     W_new\u001b[38;5;241m=\u001b[39m\u001b[43mExpX_stiefel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdir_tan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43mW\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     W\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m=\u001b[39mW_new\n",
      "File \u001b[0;32m/data/ProstateContrastiveSPD/spdnetwork/optimizers.py:133\u001b[0m, in \u001b[0;36mExpX_stiefel\u001b[0;34m(x, X)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(a\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(a\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]):\n\u001b[1;32m    132\u001b[0m         \u001b[38;5;66;03m# q,_=th.qr(a[i,j])\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m         q,_\u001b[38;5;241m=\u001b[39m\u001b[43mgram_schmidt\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m         Q[i,j]\u001b[38;5;241m=\u001b[39mq\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Q\n",
      "File \u001b[0;32m/data/ProstateContrastiveSPD/spdnetwork/optimizers.py:146\u001b[0m, in \u001b[0;36mgram_schmidt\u001b[0;34m(V)\u001b[0m\n\u001b[1;32m    144\u001b[0m n,N\u001b[38;5;241m=\u001b[39mV\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;66;03m#dimension, cardinal\u001b[39;00m\n\u001b[1;32m    145\u001b[0m W\u001b[38;5;241m=\u001b[39mth\u001b[38;5;241m.\u001b[39mzeros_like(V)\n\u001b[0;32m--> 146\u001b[0m R\u001b[38;5;241m=\u001b[39m\u001b[43mth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43mN\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdouble\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mV\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m W[:,\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m=\u001b[39mV[:,\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m/\u001b[39mth\u001b[38;5;241m.\u001b[39mnorm(V[:,\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    148\u001b[0m R[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m=\u001b[39mW[:,\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdot(V[:,\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "args = {\n",
    "                'subsampling_strategy':{\n",
    "                    'name': 'subsampling_criteria',\n",
    "                    'percentage': None\n",
    "                },\n",
    "                'optimizer':{\n",
    "                    'kind': 'Mix_RMSprop',\n",
    "                    'learning_rate': 1e-6,\n",
    "                    'momentum': 0.6\n",
    "                },\n",
    "                'loss_function': {\n",
    "                        'kind': 'CombinedLoss',\n",
    "                        'margin': 0.05,\n",
    "                        'temperature': 0.07,\n",
    "                        'mining': {\n",
    "                            'positives': 'easy',\n",
    "                            'negatives': 'semihard'\n",
    "                        }\n",
    "                },\n",
    "                'number_folds': 5,\n",
    "                'backbone_name': 'Contrastive_CB3_Combined',\n",
    "                'data': 'mertash',\n",
    "                'sequence_embedding_features': 18432, #Para SPD TS 2080, para solo AC: 18432\n",
    "                'target_shape': (12, 32, 32),\n",
    "                'batch_size': 32,\n",
    "                'epochs': 3,\n",
    "                    }\n",
    "run_k_fold(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Con porcentajes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for percentage in [40]:\n",
    "    \n",
    "    train_data_percentage = percentage / 100\n",
    "    args = {\n",
    "                        'subsampling_strategy':{\n",
    "                            'name': 'subsampling_criteria',\n",
    "                            'percentage': train_data_percentage\n",
    "                        },\n",
    "                        'optimizer':{\n",
    "                            'kind': 'Mix_RMSprop',\n",
    "                            'learning_rate': 0.01,\n",
    "                            'momentum': 0.6\n",
    "                        },\n",
    "                        'loss_function': {\n",
    "                                'kind': 'CombinedLoss',\n",
    "                                'margin': 0.05,\n",
    "                                'temperature': 0.07,\n",
    "                                'mining': {\n",
    "                                    'positives': 'easy',\n",
    "                                    'negatives': 'semihard'\n",
    "                                }\n",
    "                        },\n",
    "                        'number_folds': 5,\n",
    "                        'backbone_name': 'Contrastive_CB3_SPD_1Bire',\n",
    "                        'data': 'mertash',\n",
    "                        'sequence_embedding_features': 2080,\n",
    "                        'target_shape': (12, 32, 32),\n",
    "                        'batch_size': 32,\n",
    "                        'epochs': 1500,\n",
    "                    }\n",
    "    run_k_fold(args)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for subsampling_criteria in ['stratified', 'reduce_negatives', 'reduce_positives', ]:\n",
    "#     for percentage in [20, 40, 60, 80, 100]:\n",
    "#         train_data_percentage = percentage / 100\n",
    "#         args = {\n",
    "#                                 'subsampling_strategy':{\n",
    "#                                     'name': subsampling_criteria,\n",
    "#                                     'percentage': train_data_percentage\n",
    "#                                 },\n",
    "#                                 'optimizer':{\n",
    "#                                     'kind': 'RMSprop',\n",
    "#                                     'learning_rate': 1e-6,\n",
    "#                                     'momentum': 0.6\n",
    "#                                 },\n",
    "#                                 'loss_function': {\n",
    "#                                         'kind': 'NTXentLoss',\n",
    "#                                         'temperature': 0.07,\n",
    "#                                         'mining': {\n",
    "#                                             'positives': None,\n",
    "#                                             'negatives': None\n",
    "#                                         }\n",
    "#                                 },\n",
    "#                                 'number_folds': 5,\n",
    "#                                 'backbone_name': 'MertashMultiParametricNetworkV2',\n",
    "#                                 'data': 'mertash',\n",
    "#                                 'sequence_embedding_features': 512,\n",
    "#                                 'target_shape': (12, 32, 32),\n",
    "#                                 'batch_size': 32,\n",
    "#                                 'epochs': 5000,\n",
    "#                             }\n",
    "#         run_k_fold(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VISUALIZANDO EMBEBIDOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CB3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " args = {\n",
    "                        'subsampling_strategy':{\n",
    "                            'name': 'subsampling_criteria',\n",
    "                            'percentage': 'train_data_percentage'\n",
    "                        },\n",
    "                        'optimizer':{\n",
    "                            'kind': 'RMSprop',\n",
    "                            'learning_rate': 1e-6,\n",
    "                            'momentum': 0.6\n",
    "                        },\n",
    "                        'loss_function': {\n",
    "                                'kind': 'TripletLoss',\n",
    "                                'temperature': 0.07,\n",
    "                                'mining': {\n",
    "                                    'positives': 'easy',\n",
    "                                    'negatives': 'semihard'\n",
    "                                }\n",
    "                        },\n",
    "                        'number_folds': 5,\n",
    "                        'backbone_name': 'Contrastive_CB3',\n",
    "                        'data': 'mertash',\n",
    "                        'sequence_embedding_features':18432,\n",
    "                        'target_shape': (12, 32, 32),\n",
    "                        'batch_size': 32,\n",
    "                        'epochs': 5000,\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'/home/jaolmosr_pupils/Cesar/Experiments/'\n",
    "# weights_path = '/data/Experiments/models/mertash_contrastive_fold_2.pt'\n",
    "weights_path = '/data/Experiments_Contrastive_CB3/models/mertash_contrastive_fold_2.pt'\n",
    "model = Contrastive_CB3(device, args['target_shape'], args['sequence_embedding_features'], 'contrastive')\n",
    "model.load_state_dict(torch.load(weights_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_validation ,y_train, y_validation, ids_train, ids_val = get_fold_of_data(2)\n",
    "\n",
    "val_data = DatasetManagement(x_validation, y_validation)\n",
    "train_data = DatasetManagement(x_train, y_train)\n",
    "test_dataset = val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(\n",
    "    dataset = test_dataset,\n",
    "    shuffle = False,\n",
    "    batch_size = args['batch_size'],\n",
    "    pin_memory=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Inicializar listas vac√≠as para almacenar las salidas y las etiquetas\n",
    "all_outputs = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    val_loss = 0.0\n",
    "    for i, data in enumerate(val_loader, 0):\n",
    "        inputs, labels = data\n",
    "        for j in range(len(inputs)):\n",
    "            inputs[j] = inputs[j].to(device).type(torch.float)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        outputs = torch.nn.functional.normalize(outputs, p=2.0)\n",
    "        # Almacenar las salidas y las etiquetas en las listas\n",
    "        all_outputs.append(outputs.cpu().detach().numpy())\n",
    "        all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "# Concatenar todas las salidas y las etiquetas\n",
    "all_outputs = np.concatenate(all_outputs, axis=0)\n",
    "all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "# Aplicar PCA\n",
    "pca = PCA(n_components=2)\n",
    "reduced = pca.fit_transform(all_outputs)\n",
    "\n",
    "# Graficar los datos reducidos, coloreando por etiqueta\n",
    "scatter = plt.scatter(reduced[:, 0], reduced[:, 1], c=all_labels)\n",
    "plt.legend(*scatter.legend_elements())\n",
    "plt.show()\n",
    "\n",
    "# Imprimir el n√∫mero de puntos graficados\n",
    "print(f'N√∫mero de puntos graficados: {len(all_outputs)}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3)  # Inicializar PCA con 3 componentes\n",
    "reduced = pca.fit_transform(all_outputs)  # Reducir la dimensionalidad de los datos\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Graficar los datos reducidos\n",
    "scatter = ax.scatter(reduced[:, 0], reduced[:, 1], reduced[:, 2], c=all_labels)\n",
    "\n",
    "# Definir las leyendas\n",
    "leyendas = ['maligno', 'benigno']\n",
    "\n",
    "# Pasar las leyendas al m√©todo legend()\n",
    "plt.legend(handles=scatter.legend_elements()[0], labels=leyendas)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CB3_SPD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "        'subsampling_strategy':{\n",
    "            'name': 'subsampling_criteria',\n",
    "            'percentage': 'train_data_percentage'\n",
    "        },\n",
    "        'optimizer':{\n",
    "            'kind': 'Mix_RMSprop',\n",
    "            'learning_rate': 1e-6,\n",
    "            'momentum': 0.6\n",
    "        },\n",
    "        'loss_function': {\n",
    "                'kind': 'NTXentLoss',\n",
    "                'temperature': 0.07,\n",
    "                'mining': {\n",
    "                    'positives': 'easy',\n",
    "                    'negatives': 'semihard'\n",
    "                }\n",
    "        },\n",
    "        'number_folds': 5,\n",
    "        'backbone_name': 'Contrastive_CB3_SPD_1Bire',\n",
    "        'data': 'mertash',\n",
    "        'sequence_embedding_features': 136,\n",
    "        'target_shape': (12, 32, 32),\n",
    "        'batch_size': 32,\n",
    "        'epochs': 5000,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path = '/data/Experiments/models/mertash_contrastive_fold_5.pt'\n",
    "model = Contrastive_CB3_SPD_1Bire(device, args['target_shape'], args['sequence_embedding_features'], 'contrastive')\n",
    "model.load_state_dict(torch.load(weights_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_validation ,y_train, y_validation, ids_train, ids_val = get_fold_of_data(2)\n",
    "\n",
    "val_data = DatasetManagement(x_validation, y_validation)\n",
    "train_data = DatasetManagement(x_train, y_train)\n",
    "test_dataset = val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(\n",
    "    dataset = test_dataset,\n",
    "    shuffle = False,\n",
    "    batch_size = args['batch_size'],\n",
    "    pin_memory=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Inicializar listas vac√≠as para almacenar las salidas y las etiquetas\n",
    "all_outputs = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    val_loss = 0.0\n",
    "    for i, data in enumerate(val_loader, 0):\n",
    "        inputs, labels = data\n",
    "        for j in range(len(inputs)):\n",
    "            inputs[j] = inputs[j].to(device).type(torch.float)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        outputs = torch.nn.functional.normalize(outputs, p=2.0)\n",
    "        # Almacenar las salidas y las etiquetas en las listas\n",
    "        all_outputs.append(outputs.cpu().detach().numpy())\n",
    "        all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "# Concatenar todas las salidas y las etiquetas\n",
    "all_outputs = np.concatenate(all_outputs, axis=0)\n",
    "all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "# Aplicar PCA\n",
    "pca = PCA(n_components=2)\n",
    "reduced = pca.fit_transform(all_outputs)\n",
    "\n",
    "# Graficar los datos reducidos, coloreando por etiqueta\n",
    "scatter = plt.scatter(reduced[:, 0], reduced[:, 1], c=all_labels)\n",
    "plt.legend(*scatter.legend_elements())\n",
    "plt.show()\n",
    "\n",
    "# Imprimir el n√∫mero de puntos graficados\n",
    "print(f'N√∫mero de puntos graficados: {len(all_outputs)}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3)  # Inicializar PCA con 3 componentes\n",
    "reduced = pca.fit_transform(all_outputs)  # Reducir la dimensionalidad de los datos\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Graficar los datos reducidos\n",
    "scatter = ax.scatter(reduced[:, 0], reduced[:, 1], reduced[:, 2], c=all_labels, alpha=0.3)\n",
    "\n",
    "# Definir las leyendas\n",
    "leyendas = ['maligno', 'benigno']\n",
    "\n",
    "# Pasar las leyendas al m√©todo legend()\n",
    "plt.legend(handles=scatter.legend_elements()[0], labels=leyendas)\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
