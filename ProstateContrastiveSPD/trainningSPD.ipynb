{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import json\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score\n",
    "from sklearn.manifold import TSNE\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score\n",
    "from spdnetwork.optimizers import  MixOptimizer \n",
    "from spdnetwork.nn import LogEig\n",
    "from Utils import get_fold_of_data\n",
    "from DatasetManagement import DatasetManagement\n",
    "from Models import Contrastive_CB3, SPDnet, SPDnet1Bire\n",
    "from spdnetwork.optimizers import MixOptimizer\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = str(1)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using percentage: Embeddings20%\n",
      "Using embeddings: embeddingsSPD\n",
      "Using device: cpu\n",
      "Starting fold 1\n",
      "------------Entrenando con la SPDnet------------\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])\n",
      "tensor([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1.])\n",
      "tensor([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.])\n",
      "tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1.,\n",
      "        1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1.])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.])\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0.])\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])\n",
      "tensor([0., 1., 0., 0.])\n",
      "Epoch 1/1500, Train Loss: 0.5269, Val Loss: 0.4835, Val Accuracy: 0.8192, Val AUC: 0.5000\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])\n",
      "tensor([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1.])\n",
      "tensor([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.])\n",
      "tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1.,\n",
      "        1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1.])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.])\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0.])\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])\n",
      "tensor([0., 1., 0., 0.])\n",
      "Epoch 2/1500, Train Loss: 0.4574, Val Loss: 0.4816, Val Accuracy: 0.8192, Val AUC: 0.5000\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])\n",
      "tensor([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1.])\n",
      "tensor([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.])\n",
      "tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1.,\n",
      "        1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1.])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.])\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0.])\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])\n",
      "tensor([0., 1., 0., 0.])\n",
      "Epoch 3/1500, Train Loss: 0.4591, Val Loss: 0.4821, Val Accuracy: 0.8192, Val AUC: 0.5000\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])\n",
      "tensor([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1.])\n",
      "tensor([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.])\n",
      "tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1.,\n",
      "        1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1.])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.])\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0.])\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])\n",
      "tensor([0., 1., 0., 0.])\n",
      "Epoch 4/1500, Train Loss: 0.4480, Val Loss: 0.4847, Val Accuracy: 0.8192, Val AUC: 0.5000\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])\n",
      "tensor([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1.])\n",
      "tensor([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.])\n",
      "tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1.,\n",
      "        1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1.])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.])\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0.])\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])\n",
      "tensor([0., 1., 0., 0.])\n",
      "Epoch 5/1500, Train Loss: 0.4569, Val Loss: 0.4790, Val Accuracy: 0.8192, Val AUC: 0.5000\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])\n",
      "tensor([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1.])\n",
      "tensor([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.])\n",
      "tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1.,\n",
      "        1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1.])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.])\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0.])\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])\n",
      "tensor([0., 1., 0., 0.])\n",
      "Epoch 6/1500, Train Loss: 0.4562, Val Loss: 0.4781, Val Accuracy: 0.8192, Val AUC: 0.5000\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])\n",
      "tensor([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1.])\n",
      "tensor([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.])\n",
      "tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1.,\n",
      "        1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1.])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.])\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0.])\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])\n",
      "tensor([0., 1., 0., 0.])\n",
      "Epoch 7/1500, Train Loss: 0.4424, Val Loss: 0.4799, Val Accuracy: 0.8192, Val AUC: 0.5000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 89\u001b[0m\n\u001b[1;32m     87\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, batch_labels\u001b[38;5;241m.\u001b[39mlong())\u001b[38;5;66;03m#Long\u001b[39;00m\n\u001b[1;32m     88\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 89\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m     running_train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     92\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m running_train_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)\n",
      "File \u001b[0;32m/data/ProstateContrastiveSPD/spdnetwork/optimizers.py:104\u001b[0m, in \u001b[0;36mMixOptimizer.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;66;03m# Doing the step for each Riemannian optimizer.\u001b[39;00m\n\u001b[0;32m--> 104\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstiefel_optim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstiefel_block_optim\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspd_optim\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m/data/ProstateContrastiveSPD/spdnetwork/optimizers.py:17\u001b[0m, in \u001b[0;36mStiefelOptim.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m W \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameters:\n\u001b[1;32m     16\u001b[0m     dir_tan\u001b[38;5;241m=\u001b[39mproj_tanX_stiefel(W\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mdata,W\u001b[38;5;241m.\u001b[39mdata)\n\u001b[0;32m---> 17\u001b[0m     W_new\u001b[38;5;241m=\u001b[39m\u001b[43mExpX_stiefel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdir_tan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43mW\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     W\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m=\u001b[39mW_new\n",
      "File \u001b[0;32m/data/ProstateContrastiveSPD/spdnetwork/optimizers.py:133\u001b[0m, in \u001b[0;36mExpX_stiefel\u001b[0;34m(x, X)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(a\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(a\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]):\n\u001b[1;32m    132\u001b[0m         \u001b[38;5;66;03m# q,_=th.qr(a[i,j])\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m         q,_\u001b[38;5;241m=\u001b[39m\u001b[43mgram_schmidt\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m         Q[i,j]\u001b[38;5;241m=\u001b[39mq\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Q\n",
      "File \u001b[0;32m/data/ProstateContrastiveSPD/spdnetwork/optimizers.py:154\u001b[0m, in \u001b[0;36mgram_schmidt\u001b[0;34m(V)\u001b[0m\n\u001b[1;32m    152\u001b[0m     proj\u001b[38;5;241m=\u001b[39mproj\u001b[38;5;241m+\u001b[39mV[:,i]\u001b[38;5;241m.\u001b[39mdot(W[:,j])\u001b[38;5;241m*\u001b[39mW[:,j]\n\u001b[1;32m    153\u001b[0m     R[j,i]\u001b[38;5;241m=\u001b[39mW[:,j]\u001b[38;5;241m.\u001b[39mdot(V[:,i])\n\u001b[0;32m--> 154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(\u001b[43misclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mV\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mproj\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDoubleTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mV\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[1;32m    155\u001b[0m     W[:,i]\u001b[38;5;241m=\u001b[39mV[:,i]\u001b[38;5;241m/\u001b[39mth\u001b[38;5;241m.\u001b[39mnorm(V[:,i])\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/data/ProstateContrastiveSPD/spdnetwork/optimizers.py:162\u001b[0m, in \u001b[0;36misclose\u001b[0;34m(a, b, rtol, atol)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21misclose\u001b[39m(a,b,rtol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-05\u001b[39m,atol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-08\u001b[39m):\n\u001b[0;32m--> 162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m (atol \u001b[38;5;241m+\u001b[39m rtol \u001b[38;5;241m*\u001b[39m b\u001b[38;5;241m.\u001b[39mabs()))\u001b[38;5;241m.\u001b[39mall()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "def load_data(fold, name, percentage):\n",
    "    train_embeddings_path = f'/data/{percentage}/{name}/fold_{fold}/train/embeddingsSPD_train.pt'\n",
    "    train_labels_path = f'/data/{percentage}/{name}/fold_{fold}/train/labelsSPD_train.pt'\n",
    "    \n",
    "    val_embeddings_path = f'/data/{percentage}/{name}/fold_{fold}/val/embeddingsSPD_val.pt'\n",
    "    val_labels_path = f'/data/{percentage}/{name}/fold_{fold}/val/labelsSPD_val.pt'\n",
    "    \n",
    "    train_embeddings = torch.load(train_embeddings_path)\n",
    "    train_labels = torch.load(train_labels_path).view(-1)\n",
    "    val_embeddings = torch.load(val_embeddings_path)\n",
    "    val_labels = torch.load(val_labels_path).view(-1)\n",
    "    \n",
    "    return train_embeddings, train_labels, val_embeddings, val_labels\n",
    "\n",
    "name_embeddings = ['embeddingsSPD', 'embeddingsTripletSPD']\n",
    "percentages_path = ['Embeddings20%', 'Embeddings40%', 'Embeddings60%', 'Embeddings80%']\n",
    "\n",
    "\n",
    "for percentage in percentages_path:\n",
    "    print(f'Using percentage: {percentage}')\n",
    "    for name in name_embeddings:\n",
    "        print(f'Using embeddings: {name}')\n",
    "\n",
    "        # Configuración de entrenamiento\n",
    "        num_folds = 5\n",
    "        batch_size = 32\n",
    "        num_epochs = 1500\n",
    "        lr = 0.001\n",
    "        lr_others = 0.0001\n",
    "        momentum = 0.6\n",
    "\n",
    "        save_path = f'/data/{percentage}/results/{name}'\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        print(f'Using device: {device}')\n",
    "\n",
    "        accuracy_list = []\n",
    "        auc_list = []\n",
    "\n",
    "        # Entrenamiento y validación en cada fold\n",
    "        for fold in range(1, num_folds + 1):\n",
    "            print(f'Starting fold {fold}')\n",
    "            \n",
    "            # Cargar datos\n",
    "            train_embeddings, train_labels, val_embeddings, val_labels = load_data(fold, name, percentage)\n",
    "            \n",
    "            train_dataset = TensorDataset(train_embeddings, train_labels)\n",
    "            val_dataset = TensorDataset(val_embeddings, val_labels)\n",
    "            \n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "            \n",
    "            model = SPDnet(device).to(device)\n",
    "            print(\"------------Entrenando con la SPDnet------------\")\n",
    "            # criterion = nn.BCEWithLogitsLoss()\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            # optimizer = optim.RMSprop(model.parameters(), lr=learning_rate)\n",
    "            optimizer_class = torch.optim.RMSprop\n",
    "            optimizer = MixOptimizer(parameters = model.parameters(),    \n",
    "                                    optimizer = optimizer_class,                                \n",
    "                                    lr = lr,\n",
    "                                    lr_others = lr_others,\n",
    "                                    momentum = momentum                               \n",
    "                                )\n",
    "            best_auc = 0\n",
    "            best_model = None\n",
    "            \n",
    "            train_losses = []\n",
    "            val_losses = []\n",
    "            \n",
    "            # Entrenamiento\n",
    "            # Parámetros para Early Stopping\n",
    "            patience = num_epochs * 0.05\n",
    "            best_val_loss = float('inf')\n",
    "            early_stopping_counter = 0\n",
    "            \n",
    "            for epoch in range(num_epochs):\n",
    "                model.train()\n",
    "                running_train_loss = 0.0\n",
    "                \n",
    "                for batch_embeddings, batch_labels in train_loader:\n",
    "                    batch_embeddings, batch_labels = batch_embeddings.to(device), batch_labels.to(device)\n",
    "                    optimizer.zero_grad()\n",
    "                    batch_embeddings = batch_embeddings.unsqueeze(1)  # Ajustar el tamaño del batch para el modelo\n",
    "                    outputs = model(batch_embeddings)\n",
    "                    loss = criterion(outputs, batch_labels.long())#Long\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    running_train_loss += loss.item()\n",
    "                    \n",
    "                train_loss = running_train_loss / len(train_loader)\n",
    "                train_losses.append(train_loss)\n",
    "            \n",
    "                # Validación\n",
    "                model.eval()\n",
    "                running_val_loss = 0.0\n",
    "\n",
    "                all_preds = []\n",
    "                all_labels = []\n",
    "            \n",
    "                with torch.no_grad():\n",
    "                        \n",
    "                    model.eval()\n",
    "                    model.to(device)\n",
    "                    for batch_embeddings, batch_labels in val_loader:\n",
    "                        batch_embeddings, batch_labels = batch_embeddings.to(device), batch_labels.to(device)\n",
    "                        print(batch_labels)\n",
    "                        batch_embeddings = batch_embeddings.unsqueeze(1)  # Ajustar el tamaño del batch para el modelo\n",
    "                        outputs = model(batch_embeddings)\n",
    "                        loss = criterion(outputs, batch_labels.long()) #Long\n",
    "                        running_val_loss += loss.item()\n",
    "                        \n",
    "                        probs = torch.softmax(outputs, dim=1)  # Usar softmax para obtener probabilidades de clases\n",
    "                        preds = torch.argmax(probs, dim=1).cpu().numpy()  # Obtener las predicciones de clase\n",
    "                        all_preds.extend(preds)\n",
    "                        all_labels.extend(batch_labels.cpu().numpy())\n",
    "            \n",
    "                val_loss = running_val_loss / len(val_loader)\n",
    "                val_losses.append(val_loss)\n",
    "                \n",
    "                accuracy = accuracy_score(all_labels, all_preds)\n",
    "                auc = roc_auc_score(all_labels, all_preds)\n",
    "                \n",
    "                #Comprobar si la perdida de valicación es mejora\n",
    "                if(val_loss < best_val_loss):\n",
    "                    best_val_loss = val_loss\n",
    "                    early_stopping_counter = 0\n",
    "                else:\n",
    "                    early_stopping_counter += 1\n",
    "            \n",
    "                if auc > best_auc:\n",
    "                    best_auc = auc\n",
    "                    best_model = model.state_dict()\n",
    "                \n",
    "                print(f'Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {accuracy:.4f}, Val AUC: {auc:.4f}')\n",
    "                \n",
    "                if early_stopping_counter >= patience:\n",
    "                    print(f'Early stopping at epoch: {epoch + 1}' )\n",
    "                    break\n",
    "            \n",
    "            accuracy_list.append(accuracy)\n",
    "            auc_list.append(auc)\n",
    "            \n",
    "            print(f'Fold {fold}, Accuracy: {accuracy}, AUC: {auc}')\n",
    "\n",
    "            # Crear la carpeta para guardar el modelo del pliegue correspondiente\n",
    "            fold_save_path = os.path.join(save_path, f'fold_{fold}')\n",
    "            os.makedirs(fold_save_path, exist_ok=True)\n",
    "            \n",
    "            # Guardar el mejor modelo\n",
    "            best_model_path = os.path.join(fold_save_path, 'best_model.pth')\n",
    "            torch.save(best_model, best_model_path)\n",
    "            \n",
    "            plt.figure()\n",
    "            plt.plot(range(1, num_epochs + 1), train_losses, label='Train Loss')\n",
    "            plt.plot(range(1, num_epochs + 1), val_losses, label='Val Loss')\n",
    "            plt.xlabel('Epochs')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.title(f'Fold {fold} Loss')\n",
    "            plt.legend()\n",
    "            plt.savefig(os.path.join(fold_save_path, 'loss_plot.png'))\n",
    "            plt.close()\n",
    "\n",
    "        # Resultados promedio\n",
    "        print(f'Mean Accuracy: {sum(accuracy_list) / num_folds}')\n",
    "        print(f'Mean AUC: {sum(auc_list) / num_folds}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ================ Métricas ================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - AUC-ROC: 0.8584, Accuracy: 0.8346\n",
      "Fold 2 - AUC-ROC: 0.8934, Accuracy: 0.8826\n",
      "Fold 3 - AUC-ROC: 0.9060, Accuracy: 0.8346\n",
      "Fold 4 - AUC-ROC: 0.9390, Accuracy: 0.9170\n",
      "Fold 5 - AUC-ROC: 0.9229, Accuracy: 0.8254\n",
      "Promedio de AUC: 0.9039180894920236\n",
      "Desviación estandar: 0.02750019449672346\n",
      "Promedio de Accuracy: 0.8588429537909554\n",
      "Desviación estandar: 0.035311247328858895\n",
      "Promedio de AUC_PR: 0.7592616269128999\n",
      "Desviación estandar: 0.033603187298336536\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_recall_curve, auc\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Definir el dispositivo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "list_auc = []\n",
    "list_accuracy = []\n",
    "list_aucpr = []\n",
    "# Definir una función para cargar los datos y etiquetas de validación\n",
    "def load_data(embeddings_path, labels_path):\n",
    "    embeddings = torch.load(embeddings_path, map_location=device)\n",
    "    labels = torch.load(labels_path, map_location=device)\n",
    "    return embeddings, labels\n",
    "\n",
    "# Definir una función para evaluar el modelo y calcular métricas\n",
    "def evaluate_model(model, val_embeddings, val_labels):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Obtener las predicciones del modelo\n",
    "        outputs = model(val_embeddings)\n",
    "        # Asumiendo que las salidas son logits, aplicar softmax para obtener probabilidades\n",
    "        probs = F.softmax(outputs, dim=1)[:, 1]  # Suponiendo que la clase positiva es la 1\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        \n",
    "        # Calcular AUC-ROC\n",
    "        auc_roc = roc_auc_score(val_labels.cpu().numpy(), probs.cpu().numpy())\n",
    "        \n",
    "        # Calcular Accuracy\n",
    "        accuracy = accuracy_score(val_labels.cpu().numpy(), preds.cpu().numpy())\n",
    "        \n",
    "        #Calcular AUCPR\n",
    "        precisions, recalls, _ = precision_recall_curve(val_labels.cpu().numpy(), probs.cpu().numpy())\n",
    "        auc_pr = auc(recalls, precisions)\n",
    "        \n",
    "        return auc_roc, accuracy, auc_pr\n",
    "\n",
    "# Path base para los datos\n",
    "base_path = \"/data/ProstateContrastiveSPD/ResultsTripletSPDembeddings\"\n",
    "\n",
    "folds = [1,2,3,4,5]  # Puedes agregar más folds aquí\n",
    "\n",
    "for fold in folds:\n",
    "    # Cargar el modelo para el fold actual\n",
    "    model_path = f\"{base_path}/SPDnet2N1BireDLinear/fold_{fold}/best_model.pth\"\n",
    "    model = SPDnet1Bire(device).to(device)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    \n",
    "    # Cargar los datos de validación\n",
    "    val_embeddings_path = f\"/data/ProstateContrastiveSPD/embeddingsTripletSPD/fold_{fold}/val/embeddingsSPD_val.pt\"\n",
    "    val_labels_path = f\"/data/ProstateContrastiveSPD/embeddingsTripletSPD/fold_{fold}/val/labelsSPD_val.pt\"\n",
    "    \n",
    "    val_embeddings, val_labels = load_data(val_embeddings_path, val_labels_path)\n",
    "    val_embeddings = val_embeddings.unsqueeze(1)\n",
    "    \n",
    "    # Evaluar el modelo y calcular métricas\n",
    "    auc_roc, accuracy, auc_pr = evaluate_model(model, val_embeddings, val_labels)\n",
    "    list_auc.append(auc_roc)\n",
    "    list_accuracy.append(accuracy)\n",
    "    list_aucpr.append(auc_pr)\n",
    "    \n",
    "    print(f\"Fold {fold} - AUC-ROC: {auc_roc:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Promedio de AUC: {np.mean(list_auc)}\")\n",
    "print(f\"Desviación estandar: {np.std(list_auc)}\")\n",
    "\n",
    "print(f\"Promedio de Accuracy: {np.mean(list_accuracy)}\")\n",
    "print(f\"Desviación estandar: {np.std(list_accuracy)}\")\n",
    "\n",
    "print(f\"Promedio de AUC_PR: {np.mean(list_aucpr)}\")\n",
    "print(f\"Desviación estandar: {np.std(list_aucpr)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
